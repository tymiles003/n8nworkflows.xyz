Extract & Analyze Competitor Backlink Data with Bright Data MCP & GPT

https://n8nworkflows.xyz/workflows/extract---analyze-competitor-backlink-data-with-bright-data-mcp---gpt-5963


# Extract & Analyze Competitor Backlink Data with Bright Data MCP & GPT

---

## 1. Workflow Overview

This workflow automates the extraction and analysis of competitor backlink data using Bright Data's MCP (Massive Cloud Proxy) scraping platform combined with OpenAI's GPT language model. It is designed primarily for SEO professionals or digital marketers who want to collect backlink profiles from competitor domains and store them in a structured format for further analysis or outreach campaigns.

The workflow is logically divided into three main blocks:

- **1.1 Input & Trigger**: Receives the competitor domain input and initiates workflow execution.
- **1.2 Agent Scrape Engine**: Uses an AI-powered scraping agent backed by Bright Data MCP proxies and OpenAI GPT to extract backlink data from the competitor’s domain.
- **1.3 Transform & Store**: Processes the raw backlink JSON output, splits it into individual backlink records, and appends them as rows into a Google Sheet for easy access and management.

---

## 2. Block-by-Block Analysis

### 1.1 Input & Trigger

**Overview:**  
This block handles user input and starts the workflow. It allows manual execution and sets the competitor domain URL that will be analyzed.

**Nodes Involved:**  
- Trigger: Manual Execute  
- Set: Competitor Domain  

**Node Details:**

- **Trigger: Manual Execute**  
  - **Type:** Manual trigger  
  - **Role:** Starts the workflow on user demand by clicking “Execute Workflow”  
  - **Configuration:** No parameters; simply triggers execution  
  - **Connections:** Output goes to “Set: Competitor Domain” node  
  - **Potential Failures:** None typical, except user forgetting to trigger  
  - **Notes:** Useful for testing or ad-hoc runs; can be replaced with a Schedule trigger for automation  

- **Set: Competitor Domain**  
  - **Type:** Set node (data assignment)  
  - **Role:** Stores the competitor’s domain URL as an input variable for downstream nodes  
  - **Configuration:** Sets a single string parameter named `url`, e.g. `https://ahrefs.com/`  
  - **Connections:** Input from Manual Trigger; output to “Agent: Scrape Backlinks (Bright Data MCP)”  
  - **Variables Used:** `$json.url` holds the competitor domain URL  
  - **Potential Failures:** Input must be a valid URL format; malformed URL may cause scraping errors  

---

### 1.2 Agent Scrape Engine

**Overview:**  
This block executes the core scraping task using a custom Agent that leverages Bright Data MCP proxies and optionally OpenAI GPT to scrape backlink data from the competitor’s site. It includes output parsing to format the data as structured JSON.

**Nodes Involved:**  
- Agent: Scrape Backlinks (Bright Data MCP)  
- MCP Client  
- OpenAI Chat Model  
- Structured Output Parser  
- Auto-fixing Output Parser  
- OpenAI Chat Model1 (optional, used downstream of output parser)

**Node Details:**

- **Agent: Scrape Backlinks (Bright Data MCP)**  
  - **Type:** Langchain Agent node  
  - **Role:** Main orchestrator that sends scraping instructions to Bright Data MCP tool, optionally uses GPT for dynamic instruction generation or parsing  
  - **Configuration:**  
    - Text prompt: `extract any backlinks available from the following url: {{ $json.url }}`  
    - Uses AI output parsers to ensure structured data  
  - **Connections:**  
    - Inputs competitor domain URL from “Set: Competitor Domain”  
    - Calls MCP Client and OpenAI Chat Model as AI tools internally  
    - Outputs raw JSON backlinks to “Function: Split Backlinks”  
  - **Credentials:** OpenAI API and Bright Data MCP credentials required  
  - **Potential Failures:**  
    - Proxy or scraping errors (blocked requests, CAPTCHA failures)  
    - OpenAI API limits or timeouts  
    - Parsing errors if output format changes  
  - **Notes:** Handles anti-bot protections via MCP’s proxy network  

- **MCP Client**  
  - **Type:** MCP client tool node  
  - **Role:** Executes the scraper tool on Bright Data’s backend via API  
  - **Configuration:** Passes tool parameters dynamically generated by the agent node  
  - **Connections:** Called internally by Agent node as AI tool  
  - **Potential Failures:** API authentication errors, network timeouts  

- **OpenAI Chat Model**  
  - **Type:** OpenAI GPT model node  
  - **Role:** Provides language model support for the Agent, e.g., for instruction generation or parsing dynamic content  
  - **Configuration:** Uses `gpt-4o-mini` model  
  - **Connections:** Called internally by Agent node as AI language model  
  - **Credentials:** OpenAI API key required  
  - **Potential Failures:** API quota limits, latency  

- **Structured Output Parser**  
  - **Type:** Langchain structured output parser node  
  - **Role:** Parses the Agent’s raw text output into structured JSON following a defined schema for backlinks (domain, backlinks array with title, url, category, date)  
  - **Configuration:** Uses a JSON schema example showing backlink data structure  
  - **Connections:** Output from “OpenAI Chat Model1” and feeds into “Auto-fixing Output Parser”  
  - **Potential Failures:** Parsing errors if output does not match schema  

- **Auto-fixing Output Parser**  
  - **Type:** Langchain output parser autofixing node  
  - **Role:** Attempts to automatically fix or clean parsing errors from previous parser  
  - **Connections:** Input from “Structured Output Parser”, output to “Agent: Scrape Backlinks (Bright Data MCP)” node (loopback for corrected data)  
  - **Potential Failures:** Infinite loop risk if parsing repeatedly fails  

- **OpenAI Chat Model1**  
  - **Type:** OpenAI GPT model node  
  - **Role:** Secondary GPT call to assist output parsing or other language tasks downstream of structured parser  
  - **Configuration:** Uses same `gpt-4o-mini` model  
  - **Connections:** Feeds into “Structured Output Parser”  

---

### 1.3 Transform & Store

**Overview:**  
This block processes the structured JSON output from the scraping agent by splitting the backlink array into individual items and appending each as a new row into a Google Sheet for organized storage and future analysis.

**Nodes Involved:**  
- Function: Split Backlinks  
- Google Sheets: Append Backlinks  

**Node Details:**

- **Function: Split Backlinks**  
  - **Type:** Code function node  
  - **Role:** Converts the backlinks array from the JSON into separate workflow items (one item per backlink)  
  - **Configuration:** JavaScript code that iterates over `input.backlinks` array, mapping each backlink’s title, url, category, and date into individual JSON objects along with the domain  
  - **Input:** JSON object with `.domain` and `.backlinks` array from Agent output  
  - **Output:** Array of individual backlink objects as separate items  
  - **Potential Failures:**  
    - Runtime errors if input JSON structure is unexpected or missing fields  
    - Empty backlink array leads to no output items  

- **Google Sheets: Append Backlinks**  
  - **Type:** Google Sheets node  
  - **Role:** Appends each backlink item as a new row in a specific Google Sheet and sheet tab  
  - **Configuration:**  
    - Operation: Append  
    - Document ID and Sheet Name set to a specific Google Sheet (e.g., Backlinks sheet)  
    - Columns mapped: domain, title, url, category, date  
  - **Credentials:** Requires Google Sheets OAuth2 credentials with write access  
  - **Input:** Items from “Function: Split Backlinks” node  
  - **Potential Failures:**  
    - Authentication errors if OAuth token invalid  
    - API rate limits on Google Sheets  
    - Schema mismatch if columns change in sheet  
  - **Notes:** Easily replaceable with Airtable or CRM nodes for other data sinks  

---

## 3. Summary Table

| Node Name                        | Node Type                                | Functional Role                         | Input Node(s)                       | Output Node(s)                      | Sticky Note                                                                                                                           |
|---------------------------------|-----------------------------------------|---------------------------------------|-----------------------------------|-----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|
| Trigger: Manual Execute          | Manual Trigger                          | Starts workflow manually on demand    | None                              | Set: Competitor Domain             | Section 1: Input & Trigger - Starts workflow manually for testing or ad-hoc runs                                                      |
| Set: Competitor Domain           | Set Node                               | Stores competitor domain URL           | Trigger: Manual Execute            | Agent: Scrape Backlinks (Bright Data MCP) | Section 1: Input & Trigger - Central place to update competitor domain                                                                |
| Agent: Scrape Backlinks (Bright Data MCP) | Langchain Agent                       | Executes scraping agent with MCP proxies and GPT | Set: Competitor Domain             | Function: Split Backlinks          | Section 2: Agent Scrape Engine - Core scraping with Bright Data MCP proxies and OpenAI GPT                                             |
| MCP Client                      | MCP Client Tool                        | Executes scraper tool on Bright Data  | Agent: Scrape Backlinks           | Agent: Scrape Backlinks           | Section 2: Agent Scrape Engine - Backend scraper execution via Bright Data MCP                                                        |
| OpenAI Chat Model               | OpenAI GPT Model                      | Provides language model support for agent | Agent: Scrape Backlinks           | Agent: Scrape Backlinks           | Section 2: Agent Scrape Engine - GPT assists in instruction generation or parsing                                                     |
| Structured Output Parser        | Langchain Structured Output Parser    | Parses raw text output into JSON      | OpenAI Chat Model1                | Auto-fixing Output Parser          | Section 2: Agent Scrape Engine - Formats output into structured JSON                                                                   |
| Auto-fixing Output Parser       | Langchain Autofixing Output Parser    | Automatically fixes parsing errors    | Structured Output Parser           | Agent: Scrape Backlinks           | Section 2: Agent Scrape Engine - Ensures clean JSON output                                                                             |
| OpenAI Chat Model1              | OpenAI GPT Model                      | Secondary GPT processing for parsing  | Auto-fixing Output Parser          | Structured Output Parser           | Section 2: Agent Scrape Engine - Additional GPT call in parsing chain                                                                 |
| Function: Split Backlinks       | Function (JavaScript)                  | Splits backlink array into separate items | Agent: Scrape Backlinks           | Google Sheets: Append Backlinks    | Section 3: Transform & Store - Prepares individual backlinks for storage                                                              |
| Google Sheets: Append Backlinks | Google Sheets Node                    | Adds backlinks as rows to Google Sheet | Function: Split Backlinks          | None                              | Section 3: Transform & Store - Stores backlink data for analysis and outreach                                                         |
| Sticky Note                    | Sticky Note                           | Documentation and explanations        | None                              | None                             | See detailed notes in workflow; multiple notes cover sections and usage guidance                                                      |

---

## 4. Reproducing the Workflow from Scratch

1. **Create a Manual Trigger node**  
   - No parameters needed. This node will start the workflow manually.

2. **Add a Set node named "Set: Competitor Domain"**  
   - Add a string field named `url`  
   - Set its value to the competitor domain URL you want to analyze, e.g., `https://ahrefs.com/`  
   - Connect the Manual Trigger output to this node’s input.

3. **Add a Langchain Agent node named "Agent: Scrape Backlinks (Bright Data MCP)"**  
   - Set the prompt text to: `extract any backlinks available from the following url:\n{{ $json.url }}`  
   - Enable output parsing  
   - Configure credentials: attach your OpenAI API credentials and Bright Data MCP credentials  
   - Connect the "Set: Competitor Domain" node output to this Agent node’s input.

4. **Add an MCP Client node**  
   - Set `toolName` to `scrape_as_markdown`  
   - Operation: `executeTool`  
   - For `toolParameters`, bind dynamically to the Agent’s generated parameters (expression)  
   - Connect this node as an AI tool inside the Agent node (this is handled internally in n8n Langchain Agent node configuration).

5. **Add an OpenAI Chat Model node** (named as in the workflow, e.g., "OpenAI Chat Model")  
   - Model: `gpt-4o-mini` or any GPT model of choice  
   - Connect as AI language model inside Agent node.

6. **Add a Structured Output Parser node**  
   - Paste the JSON schema example for backlinks as provided (with domain and backlinks array containing title, url, category, date)  
   - Connect output of OpenAI Chat Model1 node to this parser.

7. **Add an Auto-fixing Output Parser node**  
   - No special parameters needed; it auto-fixes parsing errors.  
   - Connect output of Structured Output Parser node to this node.

8. **Add a second OpenAI Chat Model node ("OpenAI Chat Model1")**  
   - Same model configuration as the first OpenAI node  
   - Connect output of Auto-fixing Output Parser to this node, then output back to Structured Output Parser (forming a parsing loop).

9. **Add a Function node named "Function: Split Backlinks"**  
   - Paste JavaScript code to extract backlinks array and map each backlink into individual items as per the workflow code.  
   - Connect output of Agent node to this Function node.

10. **Add a Google Sheets node named "Google Sheets: Append Backlinks"**  
    - Operation: Append  
    - Provide Google Sheets Document ID and Sheet Name (e.g., `Backlinks` sheet)  
    - Map columns: domain, title, url, category, date to corresponding fields from the Function node output.  
    - Connect output of Function node to this Google Sheets node.  
    - Configure Google Sheets OAuth2 credentials.

11. **Connect all nodes appropriately:**  
    Manual Trigger → Set: Competitor Domain → Agent: Scrape Backlinks → Function: Split Backlinks → Google Sheets Append

12. **Optional:** Add Sticky Notes for documentation and explanation in the workflow editor.

---

## 5. General Notes & Resources

| Note Content                                                                                                               | Context or Link                                                                                 |
|----------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|
| I’ll receive a tiny commission if you join Bright Data through this link—thanks for fueling more free content!              | https://get.brightdata.com/1tndi4600b25                                                        |
| Workflow support and contact: Yaron@nofluff.online                                                                         |                                                                                               |
| More tips and tutorials available on YouTube and LinkedIn by Yaron Been                                                     | YouTube: https://www.youtube.com/@YaronBeen/videos<br>LinkedIn: https://www.linkedin.com/in/yaronbeen/ |

---

**Disclaimer:**  
This documentation is generated from an n8n workflow automation and complies with all current content policies. It contains no illegal or protected content and only processes legal and publicly available data.

---